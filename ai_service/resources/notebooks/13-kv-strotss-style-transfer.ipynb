{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "# STROTSS Style Transfer Notebook"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#### [Style Transfer by Relaxed Optimal Transport and Self-Similarity (STROTSS)](https://arxiv.org/abs/1904.12785)\n",
    "Code from: https://github.com/futscdav/strotss\n",
    "Notebook by: Peter Schaldenbrand"
   ],
   "id": "33072731c06cb9ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download the strotss code from GitHub",
   "id": "586b612c08096846"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "if not os.path.exists('/content/strotss'):\n",
    "    !git clone https://github.com/futscdav/strotss.git\n",
    "os.chdir('/content/strotss')\n",
    "from strotss import *"
   ],
   "id": "441c4732660975fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helper Functions",
   "id": "70cfd77f92cea1cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import requests\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if not torch.cuda.is_available():\n",
    "    print('YOU ARE NOT USING A GPU.  IT\\'S GONNA BE REAAALLLLY SLOW')\n",
    "    print('Go to the top of the page.  Click Runtime -> Change Runtime Type -> Hardware accelerator')\n",
    "    print('From the dropdown, select GPU and rerun all this stuff')\n",
    "\n",
    "def pil_loader_internet(url):\n",
    "    response = requests.get(url)\n",
    "    img = PIL.Image.open(BytesIO(response.content))\n",
    "    return img.convert('RGB')\n",
    "\n",
    "def show_img(img):\n",
    "    # Code for displaying at actual resolution from:\n",
    "    # https://stackoverflow.com/questions/28816046/displaying-different-images-with-actual-size-in-matplotlib-subplot\n",
    "    dpi = 80\n",
    "    height, width, depth = img.shape\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_style_and_content(style, content):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "    ax[0].imshow(content)\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    ax[0].set_title('Content')\n",
    "    ax[1].imshow(style)\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "    ax[1].set_title('Style')\n",
    "    plt.show()"
   ],
   "id": "abbbc71e011e3cf0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define STROTSS function",
   "id": "97cef1e8cdf06239"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Redefine the STROTSS function to put some debugging statements in\n",
    "\n",
    "def strotss(content_pil, style_pil, content_weight=1.0*16.0, device='cuda:0', space='uniform'):\n",
    "    content_np = pil_to_np(content_pil)\n",
    "    style_np = pil_to_np(style_pil)\n",
    "    content_full = np_to_tensor(content_np, space).to(device)\n",
    "    style_full = np_to_tensor(style_np, space).to(device)\n",
    "\n",
    "    lr = 2e-3\n",
    "    extractor = Vgg16_Extractor(space=space).to(device)\n",
    "\n",
    "    scale_last = max(content_full.shape[2], content_full.shape[3])\n",
    "    scales = []\n",
    "    for scale in range(10):\n",
    "        divisor = 2**scale\n",
    "        if min(content_pil.width, content_pil.height) // divisor >= 33:\n",
    "            scales.insert(0, divisor)\n",
    "    \n",
    "    clow = -1.0 if space == 'uniform' else -1.7\n",
    "    chigh = 1.0 if space == 'uniform' else 1.7\n",
    "\n",
    "    for scale in scales:\n",
    "        # rescale content to current scale\n",
    "        content = tensor_resample(content_full, [ content_full.shape[2] // scale, content_full.shape[3] // scale ])\n",
    "        style = tensor_resample(style_full, [ style_full.shape[2] // scale, style_full.shape[3] // scale ])\n",
    "        print(f'Optimizing at resoluton [{content.shape[2]}, {content.shape[3]}]')\n",
    "\n",
    "        # upsample or initialize the result\n",
    "        if scale == scales[0]:\n",
    "            # first\n",
    "            result = laplacian(content) + style.mean(2,keepdim=True).mean(3,keepdim=True)\n",
    "        elif scale == scales[-1]:\n",
    "            # last \n",
    "            result = tensor_resample(result, [content.shape[2], content.shape[3]])\n",
    "            lr = 1e-3\n",
    "        else:\n",
    "            result = tensor_resample(result, [content.shape[2], content.shape[3]]) + laplacian(content)\n",
    "\n",
    "        # do the optimization on this scale\n",
    "        result = optimize(result, content, style, scale, content_weight=content_weight, lr=lr, extractor=extractor)\n",
    "\n",
    "        # Show intermediate result\n",
    "        result_image = tensor_to_np(torch.clamp(result, clow, chigh)) # \n",
    "        # renormalize image\n",
    "        result_image -= result_image.min()\n",
    "        result_image /= result_image.max()\n",
    "        show_img(result_image)\n",
    "\n",
    "        # next scale lower weight\n",
    "        content_weight /= 2.0\n",
    "\n",
    "    result_image = tensor_to_np(tensor_resample(torch.clamp(result, clow, chigh), [content_full.shape[2], content_full.shape[3]])) # \n",
    "    # renormalize image\n",
    "    result_image -= result_image.min()\n",
    "    result_image /= result_image.max()\n",
    "    return np_to_pil(result_image * 255.)\n",
    "\n",
    "#@title Run STROTSS\n",
    "#@markdown Put publicly accessible URLs to images for content_url and style_url\n",
    "content_url = 'https://mymodernmet.com/wp/wp-content/uploads/2021/08/frog-photos-ajar-setiadi-4.jpeg'  #@param {type:\"string\"}\n",
    "style_url = 'https://m.media-amazon.com/images/I/91iS91eizUL._AC_SL1500_.jpg'  #@param {type:\"string\"}\n",
    "\n",
    "content_pil = pil_loader_internet(content_url)\n",
    "style_pil = pil_loader_internet(style_url)\n",
    "plot_style_and_content(style_pil, content_pil)\n",
    "\n",
    "max_width = 512  #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown How much weight to give to content. \n",
    "content_weight = 0.5 #@param {type:\"number\"}\n",
    "content_weight *= 16.0 \n",
    "\n",
    "result = strotss(pil_resize_long_edge_to(content_pil, max_width), \n",
    "        pil_resize_long_edge_to(style_pil, max_width), \n",
    "        content_weight, device, \"vgg\")\n",
    "print('Final Result')\n",
    "show_img(pil_to_np(result))"
   ],
   "id": "c61c5141e66056c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
